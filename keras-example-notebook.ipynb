{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "* data_dir: directory of the dataset\n",
    "* save_dir: directory of the model\n",
    "* labeling_method: 'NPWE4i' or 'NPWEf' or 'DDOGCHOi'\n",
    "* training_testing_scheme: 1 or 2 or 3  \n",
    "* data_case:  \n",
    "    * if training_testing_scheme = 1, it is the noise structure to be examined (choose any number from 1 to 12)  \n",
    "    * if training_testing_scheme = 2 or 3, it is the viewing image plane to be examined (1 for transverse plane, 2 for longitudinal plane)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:/DATA/'\n",
    "save_dir = 'D:/RESULTS/'\n",
    "labeling_method = 'NPWE4i'\n",
    "training_testing_scheme = 1\n",
    "data_case = 1\n",
    "\n",
    "model_name = labeling_method + '_scheme' + str(training_testing_scheme)+'_case'+str(data_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Training Sets\n",
    "\n",
    "* The total datasets are divided into training, validation, and testing sets with the ratio 2:1:1.\n",
    "\n",
    "* Note 1: The dimension order of .mat file is originally (rows, cols, depth, batch)  \n",
    "* Note 2: The dimension order of .mat file (version 7.3) is reversed when loaded with h5py, which is (batch, depth, cols, rows)  \n",
    "* Note 3: The shape of 3D data for tensorflow is (batch, rows, cols, depth, channels).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_processing == true.\n",
      "Training image shape: (4000, 129, 129, 1)\n",
      "Training label shape: (4000, 1)\n",
      "Validation image shape: (2000, 129, 129, 1)\n",
      "Validation label shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from scipy import io\n",
    "\n",
    "train_list = {\n",
    "    1: [data_case],\n",
    "    2: list(range(6*(data_case-1)+1,6*data_case+1)),\n",
    "    3: list(range(6*(data_case-1)+1,6*data_case+1))\n",
    "}[training_testing_scheme]\n",
    "\n",
    "N_PA = 4000 # number of image pairs (g1 and g0)\n",
    "N_TR = 2000 # number of training pairs\n",
    "N_VA = 1000 # number of validation pairs\n",
    "N_TE = 1000 # number of testing pairs\n",
    "\n",
    "input_processing = True # make DC component to zero\n",
    "\n",
    "random_seed_number = 3 # shuffling training and validation sets.\n",
    "np.random.seed(random_seed_number)\n",
    "idx_seq1 = np.random.permutation(N_TR+N_VA)\n",
    "idx_seq0 = np.random.permutation(N_TR+N_VA)\n",
    "\n",
    "for i in range(0,len(train_list)):\n",
    "\n",
    "    filename = data_dir+'N'+str(train_list[i])+'_g1.mat'\n",
    "    f = h5py.File(filename,'r')\n",
    "    g1_temp = np.asarray(f['g1'])\n",
    "    \n",
    "    filename = data_dir+'N'+str(train_list[i])+'_g0.mat'\n",
    "    f = h5py.File(filename,'r')\n",
    "    g0_temp = np.asarray(f['g0'])\n",
    "    \n",
    "    filename = data_dir+'label_N'+str(train_list[i])+'_'+labeling_method+'.mat'\n",
    "    f = io.loadmat(filename)\n",
    "    t1_temp = np.asarray(f['t1'])\n",
    "    t1_temp = np.transpose(t1_temp, (1,0))\n",
    "    t0_temp = np.asarray(f['t0'])\n",
    "    t0_temp = np.transpose(t0_temp, (1,0))\n",
    "        \n",
    "    g1_temp = g1_temp[idx_seq1,:,:]\n",
    "    t1_temp = t1_temp[idx_seq1]\n",
    "    g0_temp = g0_temp[idx_seq0,:,:]\n",
    "    t0_temp = t0_temp[idx_seq0]\n",
    "            \n",
    "    if i == 0:\n",
    "        imgs = np.concatenate((g1_temp[:N_TR,:,:],g0_temp[:N_TR,:,:]),axis=0)\n",
    "        imgs_val = np.concatenate((g1_temp[N_TR:N_TR+N_VA,:,:],g0_temp[N_TR:N_TR+N_VA,:,:]),axis=0)\n",
    "        \n",
    "        labels = np.concatenate((t1_temp[:N_TR],t0_temp[:N_TR]),axis=0)\n",
    "        labels_val = np.concatenate((t1_temp[N_TR:N_TR+N_VA],t0_temp[N_TR:N_TR+N_VA]),axis=0)\n",
    "        \n",
    "    else:\n",
    "        imgs = np.concatenate((imgs, g1_temp[:N_TR,:,:],g0_temp[:N_TR,:,:]), axis = 0)\n",
    "        imgs_val = np.concatenate((imgs_val, g1_temp[N_TR:N_TR+N_VA,:,:],g0_temp[N_TR:N_TR+N_VA,:,:]), axis = 0)\n",
    "        \n",
    "        labels = np.concatenate((labels, t1_temp[:N_TR],t0_temp[:N_TR]), axis = 0) \n",
    "        labels_val = np.concatenate((labels_val, t1_temp[N_TR:N_TR+N_VA],t0_temp[N_TR:N_TR+N_VA]), axis = 0) \n",
    "\n",
    "imgs = np.transpose(imgs, (0,2,1))\n",
    "imgs_val = np.transpose(imgs_val, (0,2,1))\n",
    "        \n",
    "imgs = imgs[...,np.newaxis]\n",
    "imgs_val = imgs_val[...,np.newaxis]\n",
    "\n",
    "if input_processing:\n",
    "    print('input_processing == true.')\n",
    "    for i in range(0, imgs.shape[0]):\n",
    "        imgs[i,:,:,0] = imgs[i,:,:,0] - np.mean(imgs[i,:,:,0])\n",
    "        if i < imgs_val.shape[0]:\n",
    "            imgs_val[i,:,:,0] = imgs_val[i,:,:,0] - np.mean(imgs_val[i,:,:,0])\n",
    "            \n",
    "if labeling_method == 'NPWE4i' or labeling_method == 'NPWEf':\n",
    "    labels = labels*1000\n",
    "    labels_val = labels_val*1000\n",
    "    \n",
    "print(f\"Training image shape: {imgs.shape}\")\n",
    "print(f\"Training label shape: {labels.shape}\")\n",
    "\n",
    "print(f\"Validation image shape: {imgs_val.shape}\")\n",
    "print(f\"Validation label shape: {labels_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. CNN Model Observer\n",
    "\n",
    "* Keras implementation of the three-layer CNN.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 129, 129, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 65, 65, 2)         340       \n",
      "_________________________________________________________________\n",
      "lrelu_conv0 (LeakyReLU)      (None, 65, 65, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 33, 33, 4)         1356      \n",
      "_________________________________________________________________\n",
      "lrelu_conv1 (LeakyReLU)      (None, 33, 33, 4)         0         \n",
      "_________________________________________________________________\n",
      "flattening (Flatten)         (None, 4356)              0         \n",
      "_________________________________________________________________\n",
      "output_value (Dense)         (None, 1)                 4357      \n",
      "=================================================================\n",
      "Total params: 6,053\n",
      "Trainable params: 6,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation, Input, LeakyReLU, ELU, GlobalAveragePooling2D, Conv1D, Conv2D, Dense, Softmax, Flatten, UpSampling2D\n",
    "from keras.layers import Dropout, BatchNormalization, Reshape, SpatialDropout2D, GaussianNoise, concatenate, MaxPooling2D, ReLU, add, concatenate\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.initializers import TruncatedNormal, glorot_normal, glorot_uniform, he_normal, he_uniform, lecun_normal, lecun_uniform\n",
    "\n",
    "def CNN_Observer(SIZE_FILTER = [5], NUM_CONV = [16], CONV_STRIDES = [1], NUM_FC = [], BN = False, ALPFA_CONV = 0.5, ALPFA_FC = 0, PAD = 'same', GAP = False):\n",
    "    INPUT_SIZE = 129\n",
    "        \n",
    "    img_input = Input(shape=(INPUT_SIZE,INPUT_SIZE,1), name='input')\n",
    "    for i in range(0,len(NUM_CONV)):    \n",
    "        if i == 0:\n",
    "            x = Conv2D(NUM_CONV[i], (SIZE_FILTER[i],SIZE_FILTER[i]), strides=CONV_STRIDES[i], \n",
    "                       padding=PAD, \n",
    "#                        kernel_initializer=TruncatedNormal(mean=0.0,stddev=0.05),\n",
    "#                        kernel_regularizer=regularizers.l1(0.01),\n",
    "                       name='conv'+str(i)\n",
    "                      )(img_input)\n",
    "        else:\n",
    "            x = Conv2D(NUM_CONV[i], (SIZE_FILTER[i],SIZE_FILTER[i]), strides=CONV_STRIDES[i], \n",
    "                       padding=PAD, \n",
    "#                        kernel_initializer=TruncatedNormal(mean=0.0,stddev=0.05),\n",
    "#                        kernel_regularizer=regularizers.l1(0.01),\n",
    "                       name='conv'+str(i)\n",
    "                      )(x)\n",
    "        \n",
    "        x = LeakyReLU(alpha=ALPFA_CONV, name='lrelu_conv'+str(i))(x)  \n",
    "        if BN == True:\n",
    "            x = BatchNormalization(name='bn_conv'+str(i))(x)\n",
    "  \n",
    "    if GAP == True:\n",
    "        x = GlobalAveragePooling2D(name='gap')(x)\n",
    "    else:\n",
    "        x = Flatten(name='flattening')(x)\n",
    "    \n",
    "    for i in range(0,len(NUM_FC)):\n",
    "        x = Dense(NUM_FC[i], \n",
    "#                   kernel_initializer=TruncatedNormal(mean=0.0,stddev=0.05),\n",
    "#                   kernel_regularizer=regularizers.l2(0.01),\n",
    "                  name='fc'+str(i))(x)\n",
    "            \n",
    "        x = LeakyReLU(alpha=ALPFA_FC, name='lrelu_fc'+str(i))(x)\n",
    "        if BN == True:\n",
    "            x = BatchNormalization(name='bn_fc'+str(i))(x)\n",
    "        \n",
    "    output_value = Dense(1, \n",
    "#                          kernel_initializer=TruncatedNormal(mean=0.0,stddev=0.05),\n",
    "#                          kernel_regularizer=regularizers.l2(0.01),\n",
    "                         name='output_value')(x)\n",
    "    \n",
    "    observer_model = Model(inputs=img_input, outputs=output_value, name='Observer')\n",
    "\n",
    "    return observer_model\n",
    "\n",
    "model_4AFC = CNN_Observer(SIZE_FILTER = [13,13], NUM_CONV = [2,4], CONV_STRIDES = [2,2], NUM_FC = [], BN = False, ALPFA_CONV = 0.0, ALPFA_FC = 0.0, PAD = 'same', GAP=False)\n",
    "model_4AFC.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. CapsNet Model Observer\n",
    "\n",
    "* Keras implementation of the three-layer CapsNet.  \n",
    "* If you want to use CapsNet, please uncomment and run following codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 129, 129, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 65, 65, 2)         340       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 33, 33, 4)         1356      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 2178, 2)           0         \n",
      "_________________________________________________________________\n",
      "DigitCaps (DigitCapsuleLayer (None, 1, 4)              17424     \n",
      "_________________________________________________________________\n",
      "norm (Lambda)                (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 19,120\n",
      "Trainable params: 19,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "# import numpy as np\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Conv2D, Dense, Input, Reshape, Lambda, Layer, Flatten\n",
    "# from keras import backend as K\n",
    "# import tensorflow as tf\n",
    "# from keras import initializers\n",
    "    \n",
    "# # Reference: https://github.com/TheAILearner/Capsule-Network/blob/master/Capsule%20Network.ipynb\n",
    "# class DigitCapsuleLayer(Layer):\n",
    "#     # creating a layer class in keras\n",
    "#     def __init__(self, Nout = 1, Nin = 33*33*2, Din = 2, Dout = 4, **kwargs):\n",
    "#         super(DigitCapsuleLayer, self).__init__(**kwargs)\n",
    "#         self.kernel_initializer = initializers.get('glorot_uniform')\n",
    "#         self.Nout = Nout\n",
    "#         self.Nin = Nin\n",
    "#         self.Din = Din\n",
    "#         self.Dout = Dout\n",
    "    \n",
    "#     def build(self, input_shape): \n",
    "#         # initialize weight matrix for each capsule in lower layer\n",
    "#         self.W = self.add_weight(shape = [self.Nout, self.Nin, self.Dout, self.Din], initializer = self.kernel_initializer, name = 'weights')\n",
    "#         self.built = True\n",
    "    \n",
    "#     def call(self, inputs):\n",
    "#         inputs = K.expand_dims(inputs, 1)\n",
    "#         inputs = K.tile(inputs, [1, self.Nout, 1, 1])\n",
    "#         # matrix multiplication b/w previous layer output and weight matrix\n",
    "#         inputs = K.map_fn(lambda x: K.batch_dot(x, self.W, [2, 3]), elems=inputs)\n",
    "#         b = tf.zeros(shape = [K.shape(inputs)[0], self.Nout, self.Nin])\n",
    "#         # routing algorithm with updating coupling coefficient c, using scalar product b/w input capsule and output capsule\n",
    "#         for i in range(3-1):\n",
    "#             c = tf.nn.softmax(b, axis=1)\n",
    "#             s = K.batch_dot(c, inputs, [2, 2])\n",
    "# #             v = squashing(s)\n",
    "#             v = s\n",
    "#             b = b + K.batch_dot(v, inputs, [2,3])\n",
    "            \n",
    "#         return v \n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return tuple([None, self.Nout, self.Dout])\n",
    "\n",
    "# def squashing(inputs):\n",
    "#     squared_norm = K.sum(K.square(inputs), axis = -1, keepdims = True)\n",
    "#     return squared_norm/(1+squared_norm) * inputs / K.sqrt(squared_norm+K.epsilon()) \n",
    "\n",
    "# def norm(inputs):\n",
    "#     return K.sqrt(K.sum(K.square(inputs), axis = -1, keepdims = False) + K.epsilon())\n",
    "\n",
    "# def CapsNet_Observer():\n",
    "    \n",
    "#     img_input = Input(shape=(129,129,1), name='input')\n",
    "    \n",
    "#     # convolution layer\n",
    "#     x = Conv2D(2, (13,13), strides = 2, activation = 'relu', padding = 'same', name='conv1')(img_input)\n",
    "    \n",
    "#     # 2-D capsule layer\n",
    "#     x = Conv2D(4, (13,13), strides = 2, activation = 'relu', padding = 'same', name='conv2')(x)\n",
    "#     x_reshaped = Reshape((33*33*2,2), name='reshape')(x)\n",
    "    \n",
    "#     # 4-D capsule layer\n",
    "#     x_DigitCaps = DigitCapsuleLayer(name='DigitCaps')(x_reshaped)\n",
    "    \n",
    "#     output_value = Lambda(norm, name='norm')(x_DigitCaps)\n",
    "\n",
    "#     observer_model =Model(inputs=img_input, outputs=output_value, name='Observer')\n",
    "    \n",
    "#     return observer_model\n",
    "\n",
    "# model_4AFC = CapsNet_Observer()\n",
    "# model_4AFC.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Model Observer\n",
    "\n",
    "* save_model_address: file path name of the best model.\n",
    "* save_history_address: file path name of learning curve.\n",
    "* save_last_epoch_address: file path name of model at the last epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The checkpoint is saved in the following address:\n",
      "D:/RESULTS/model_NPWE4i_scheme1_case1\n",
      "0 epoch \n",
      "4000/4000 [==============================] - 2s 571us/step - loss: 5.7780 - val_RMSE_in_Pc: 0.1078 - val_loss: 5.2566\n",
      "1 epoch \n",
      "4000/4000 [==============================] - 2s 447us/step - loss: 3.7664 - val_RMSE_in_Pc: 0.0921 - val_loss: 2.1837\n",
      "2 epoch \n",
      "4000/4000 [==============================] - 2s 450us/step - loss: 1.9426 - val_RMSE_in_Pc: 0.1092 - val_loss: 2.1118\n",
      "3 epoch \n",
      "4000/4000 [==============================] - 2s 451us/step - loss: 1.7239 - val_RMSE_in_Pc: 0.1141 - val_loss: 1.7368\n",
      "4 epoch \n",
      "4000/4000 [==============================] - 2s 452us/step - loss: 1.6004 - val_RMSE_in_Pc: 0.1150 - val_loss: 1.7174\n",
      "5 epoch \n",
      "4000/4000 [==============================] - 2s 450us/step - loss: 1.5507 - val_RMSE_in_Pc: 0.1082 - val_loss: 1.6649\n",
      "6 epoch \n",
      "4000/4000 [==============================] - 2s 457us/step - loss: 1.4908 - val_RMSE_in_Pc: 0.1105 - val_loss: 1.6422\n",
      "Model Saved (ValPC) \n",
      "7 epoch \n",
      "4000/4000 [==============================] - 2s 451us/step - loss: 1.4848 - val_RMSE_in_Pc: 0.1075 - val_loss: 1.6376\n",
      "Model Saved (ValPC) \n",
      "8 epoch \n",
      "4000/4000 [==============================] - 2s 456us/step - loss: 1.4527 - val_RMSE_in_Pc: 0.0967 - val_loss: 1.6706\n",
      "Model Saved (ValPC) \n",
      "9 epoch \n",
      "4000/4000 [==============================] - 2s 456us/step - loss: 1.4496 - val_RMSE_in_Pc: 0.1079 - val_loss: 1.6386\n",
      "10 epoch \n",
      "4000/4000 [==============================] - 2s 457us/step - loss: 1.4006 - val_RMSE_in_Pc: 0.1158 - val_loss: 1.6505\n",
      "11 epoch \n",
      "4000/4000 [==============================] - 2s 455us/step - loss: 1.3893 - val_RMSE_in_Pc: 0.1143 - val_loss: 1.6631\n",
      "12 epoch \n",
      "4000/4000 [==============================] - 2s 458us/step - loss: 1.3755 - val_RMSE_in_Pc: 0.1062 - val_loss: 1.6435\n",
      "13 epoch \n",
      "4000/4000 [==============================] - 2s 458us/step - loss: 1.3817 - val_RMSE_in_Pc: 0.1104 - val_loss: 1.6972\n",
      "14 epoch \n",
      "4000/4000 [==============================] - 2s 470us/step - loss: 1.3247 - val_RMSE_in_Pc: 0.1057 - val_loss: 1.6356\n",
      "15 epoch \n",
      "4000/4000 [==============================] - 2s 452us/step - loss: 1.3315 - val_RMSE_in_Pc: 0.1127 - val_loss: 1.6560\n",
      "16 epoch \n",
      "4000/4000 [==============================] - 2s 456us/step - loss: 1.3078 - val_RMSE_in_Pc: 0.1111 - val_loss: 1.6342\n",
      "17 epoch \n",
      "4000/4000 [==============================] - 2s 466us/step - loss: 1.3017 - val_RMSE_in_Pc: 0.1119 - val_loss: 1.6813\n",
      "18 epoch \n",
      "4000/4000 [==============================] - 2s 455us/step - loss: 1.2823 - val_RMSE_in_Pc: 0.1113 - val_loss: 1.6347\n",
      "19 epoch \n",
      "4000/4000 [==============================] - 2s 455us/step - loss: 1.2625 - val_RMSE_in_Pc: 0.1089 - val_loss: 1.6472\n",
      "20 epoch \n",
      "4000/4000 [==============================] - 2s 458us/step - loss: 1.2362 - val_RMSE_in_Pc: 0.1082 - val_loss: 1.7272\n",
      "21 epoch \n",
      "4000/4000 [==============================] - 2s 467us/step - loss: 1.2407 - val_RMSE_in_Pc: 0.1085 - val_loss: 1.6590\n",
      "22 epoch \n",
      "4000/4000 [==============================] - 2s 458us/step - loss: 1.2176 - val_RMSE_in_Pc: 0.1094 - val_loss: 1.6774\n",
      "23 epoch \n",
      "4000/4000 [==============================] - 2s 457us/step - loss: 1.1900 - val_RMSE_in_Pc: 0.1033 - val_loss: 1.6810\n",
      "24 epoch \n",
      "4000/4000 [==============================] - 2s 448us/step - loss: 1.1721 - val_RMSE_in_Pc: 0.1013 - val_loss: 1.6983\n",
      "25 epoch \n",
      "4000/4000 [==============================] - 2s 452us/step - loss: 1.1844 - val_RMSE_in_Pc: 0.1074 - val_loss: 1.7675\n",
      "26 epoch \n",
      "4000/4000 [==============================] - 2s 458us/step - loss: 1.1587 - val_RMSE_in_Pc: 0.0973 - val_loss: 1.7076\n",
      "27 epoch \n",
      "4000/4000 [==============================] - 2s 458us/step - loss: 1.1401 - val_RMSE_in_Pc: 0.0995 - val_loss: 1.7397\n",
      "28 epoch \n",
      "4000/4000 [==============================] - 2s 457us/step - loss: 1.1507 - val_RMSE_in_Pc: 0.1037 - val_loss: 1.7716\n",
      "29 epoch \n",
      "4000/4000 [==============================] - 2s 449us/step - loss: 1.1188 - val_RMSE_in_Pc: 0.0982 - val_loss: 1.7723\n",
      "30 epoch \n",
      "4000/4000 [==============================] - 2s 463us/step - loss: 1.0908 - val_RMSE_in_Pc: 0.0968 - val_loss: 1.7889\n",
      "31 epoch \n",
      "4000/4000 [==============================] - 2s 460us/step - loss: 1.1037 - val_RMSE_in_Pc: 0.0962 - val_loss: 1.7741\n",
      "Model Saved (ValPC) \n",
      "32 epoch \n",
      "4000/4000 [==============================] - 2s 463us/step - loss: 1.0503 - val_RMSE_in_Pc: 0.0992 - val_loss: 1.8150\n",
      "33 epoch \n",
      "4000/4000 [==============================] - 2s 463us/step - loss: 1.0674 - val_RMSE_in_Pc: 0.0939 - val_loss: 1.8048\n",
      "Model Saved (ValPC) \n",
      "34 epoch \n",
      "4000/4000 [==============================] - 2s 456us/step - loss: 1.0323 - val_RMSE_in_Pc: 0.0936 - val_loss: 1.8321\n",
      "Model Saved (ValPC) \n",
      "35 epoch \n",
      "4000/4000 [==============================] - 2s 447us/step - loss: 1.0055 - val_RMSE_in_Pc: 0.0920 - val_loss: 1.8364\n",
      "Model Saved (ValPC) \n",
      "36 epoch \n",
      "4000/4000 [==============================] - 2s 450us/step - loss: 0.9922 - val_RMSE_in_Pc: 0.0823 - val_loss: 1.8380\n",
      "Model Saved (ValPC) \n",
      "37 epoch \n",
      "4000/4000 [==============================] - 2s 460us/step - loss: 0.9825 - val_RMSE_in_Pc: 0.0859 - val_loss: 1.8461\n",
      "38 epoch \n",
      "4000/4000 [==============================] - 2s 446us/step - loss: 0.9557 - val_RMSE_in_Pc: 0.0822 - val_loss: 1.9484\n",
      "Model Saved (ValPC) \n",
      "39 epoch \n",
      "4000/4000 [==============================] - 2s 455us/step - loss: 0.9388 - val_RMSE_in_Pc: 0.0832 - val_loss: 1.8796\n",
      "40 epoch \n",
      "4000/4000 [==============================] - 2s 451us/step - loss: 0.9356 - val_RMSE_in_Pc: 0.0936 - val_loss: 1.9860\n",
      "41 epoch \n",
      "4000/4000 [==============================] - 2s 456us/step - loss: 0.9375 - val_RMSE_in_Pc: 0.0779 - val_loss: 1.8965\n",
      "Model Saved (ValPC) \n",
      "42 epoch \n",
      "4000/4000 [==============================] - 2s 452us/step - loss: 0.8903 - val_RMSE_in_Pc: 0.0836 - val_loss: 2.1886\n",
      "43 epoch \n",
      "4000/4000 [==============================] - 2s 455us/step - loss: 0.8971 - val_RMSE_in_Pc: 0.0781 - val_loss: 1.9346\n",
      "44 epoch \n",
      "4000/4000 [==============================] - 2s 468us/step - loss: 0.8715 - val_RMSE_in_Pc: 0.0805 - val_loss: 1.9563\n",
      "45 epoch \n",
      "4000/4000 [==============================] - 2s 464us/step - loss: 0.8361 - val_RMSE_in_Pc: 0.0719 - val_loss: 1.9794\n",
      "Model Saved (ValPC) \n",
      "46 epoch \n",
      "4000/4000 [==============================] - 2s 466us/step - loss: 0.8234 - val_RMSE_in_Pc: 0.0745 - val_loss: 1.9921\n",
      "47 epoch \n",
      "4000/4000 [==============================] - 2s 462us/step - loss: 0.7968 - val_RMSE_in_Pc: 0.0672 - val_loss: 2.0853\n",
      "Model Saved (ValPC) \n",
      "48 epoch \n",
      "4000/4000 [==============================] - 2s 458us/step - loss: 0.7972 - val_RMSE_in_Pc: 0.0739 - val_loss: 2.1034\n",
      "49 epoch \n",
      "4000/4000 [==============================] - 2s 469us/step - loss: 0.7718 - val_RMSE_in_Pc: 0.0677 - val_loss: 2.1010\n",
      "50 epoch \n",
      "4000/4000 [==============================] - 2s 463us/step - loss: 0.7652 - val_RMSE_in_Pc: 0.0620 - val_loss: 2.0527\n",
      "Model Saved (ValPC) \n",
      "51 epoch \n",
      "4000/4000 [==============================] - 2s 470us/step - loss: 0.7324 - val_RMSE_in_Pc: 0.0660 - val_loss: 2.1310\n",
      "52 epoch \n",
      "4000/4000 [==============================] - 2s 462us/step - loss: 0.7372 - val_RMSE_in_Pc: 0.0623 - val_loss: 2.1273\n",
      "53 epoch \n",
      "4000/4000 [==============================] - 2s 454us/step - loss: 0.7614 - val_RMSE_in_Pc: 0.0625 - val_loss: 2.1260\n",
      "54 epoch \n",
      "4000/4000 [==============================] - 2s 453us/step - loss: 0.6867 - val_RMSE_in_Pc: 0.0516 - val_loss: 2.2295\n",
      "Model Saved (ValPC) \n",
      "55 epoch \n",
      "4000/4000 [==============================] - 2s 455us/step - loss: 0.6730 - val_RMSE_in_Pc: 0.0590 - val_loss: 2.2158\n",
      "56 epoch \n",
      "4000/4000 [==============================] - 2s 456us/step - loss: 0.6586 - val_RMSE_in_Pc: 0.0486 - val_loss: 2.2077\n",
      "Model Saved (ValPC) \n",
      "57 epoch \n",
      "4000/4000 [==============================] - 2s 457us/step - loss: 0.6369 - val_RMSE_in_Pc: 0.0509 - val_loss: 2.2617\n",
      "58 epoch \n",
      "4000/4000 [==============================] - 2s 458us/step - loss: 0.6324 - val_RMSE_in_Pc: 0.0481 - val_loss: 2.2476\n",
      "Model Saved (ValPC) \n",
      "59 epoch \n",
      "4000/4000 [==============================] - 2s 469us/step - loss: 0.6450 - val_RMSE_in_Pc: 0.0413 - val_loss: 2.2587\n",
      "Model Saved (ValPC) \n",
      "60 epoch \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 2s 450us/step - loss: 0.6165 - val_RMSE_in_Pc: 0.0529 - val_loss: 2.3220\n",
      "61 epoch \n",
      "4000/4000 [==============================] - 2s 455us/step - loss: 0.5868 - val_RMSE_in_Pc: 0.0382 - val_loss: 2.3043\n",
      "Model Saved (ValPC) \n",
      "62 epoch \n",
      "4000/4000 [==============================] - 2s 476us/step - loss: 0.5681 - val_RMSE_in_Pc: 0.0457 - val_loss: 2.3832\n",
      "63 epoch \n",
      "4000/4000 [==============================] - 2s 455us/step - loss: 0.5593 - val_RMSE_in_Pc: 0.0338 - val_loss: 2.3646\n",
      "Model Saved (ValPC) \n",
      "64 epoch \n",
      "4000/4000 [==============================] - 2s 465us/step - loss: 0.5379 - val_RMSE_in_Pc: 0.0390 - val_loss: 2.3875\n",
      "65 epoch \n",
      "4000/4000 [==============================] - 2s 458us/step - loss: 0.5393 - val_RMSE_in_Pc: 0.0368 - val_loss: 2.4279\n",
      "66 epoch \n",
      "4000/4000 [==============================] - 2s 456us/step - loss: 0.5143 - val_RMSE_in_Pc: 0.0230 - val_loss: 2.4148\n",
      "Model Saved (ValPC) \n",
      "67 epoch \n",
      "4000/4000 [==============================] - 2s 454us/step - loss: 0.5141 - val_RMSE_in_Pc: 0.0293 - val_loss: 2.7364\n",
      "68 epoch \n",
      "4000/4000 [==============================] - 2s 453us/step - loss: 0.5081 - val_RMSE_in_Pc: 0.0346 - val_loss: 2.5200\n",
      "69 epoch \n",
      "4000/4000 [==============================] - 2s 457us/step - loss: 0.5158 - val_RMSE_in_Pc: 0.0276 - val_loss: 2.5120\n",
      "70 epoch \n",
      "4000/4000 [==============================] - 2s 453us/step - loss: 0.4959 - val_RMSE_in_Pc: 0.0271 - val_loss: 2.5256\n",
      "71 epoch \n",
      "4000/4000 [==============================] - 2s 453us/step - loss: 0.4803 - val_RMSE_in_Pc: 0.0189 - val_loss: 2.5169\n",
      "Model Saved (ValPC) \n",
      "72 epoch \n",
      "4000/4000 [==============================] - 2s 456us/step - loss: 0.4552 - val_RMSE_in_Pc: 0.0186 - val_loss: 2.5909\n",
      "Model Saved (ValPC) \n",
      "73 epoch \n",
      "4000/4000 [==============================] - 2s 458us/step - loss: 0.4857 - val_RMSE_in_Pc: 0.0132 - val_loss: 2.5440\n",
      "Model Saved (ValPC) \n",
      "74 epoch \n",
      "4000/4000 [==============================] - 2s 472us/step - loss: 0.4322 - val_RMSE_in_Pc: 0.0099 - val_loss: 2.5845\n",
      "Model Saved (ValPC) \n",
      "75 epoch \n",
      "4000/4000 [==============================] - 2s 455us/step - loss: 0.4591 - val_RMSE_in_Pc: 0.0268 - val_loss: 2.6308\n",
      "76 epoch \n",
      "4000/4000 [==============================] - 2s 458us/step - loss: 0.4234 - val_RMSE_in_Pc: 0.0142 - val_loss: 2.6602\n",
      "77 epoch \n",
      "4000/4000 [==============================] - 2s 457us/step - loss: 0.4277 - val_RMSE_in_Pc: 0.0083 - val_loss: 2.7798\n",
      "Model Saved (ValPC) \n",
      "78 epoch \n",
      "4000/4000 [==============================] - 2s 470us/step - loss: 0.4124 - val_RMSE_in_Pc: 0.0137 - val_loss: 2.7269\n",
      "79 epoch \n",
      "4000/4000 [==============================] - 2s 451us/step - loss: 0.4348 - val_RMSE_in_Pc: 0.0047 - val_loss: 2.6999\n",
      "Model Saved (ValPC) \n",
      "80 epoch \n",
      "4000/4000 [==============================] - 2s 451us/step - loss: 0.3986 - val_RMSE_in_Pc: 0.0152 - val_loss: 2.7339\n",
      "81 epoch \n",
      "4000/4000 [==============================] - 2s 451us/step - loss: 0.3839 - val_RMSE_in_Pc: 0.0056 - val_loss: 2.7590\n",
      "82 epoch \n",
      "4000/4000 [==============================] - 2s 449us/step - loss: 0.3645 - val_RMSE_in_Pc: 0.0079 - val_loss: 2.7739\n",
      "83 epoch \n",
      "4000/4000 [==============================] - 2s 451us/step - loss: 0.3630 - val_RMSE_in_Pc: 0.0016 - val_loss: 2.8024\n",
      "Model Saved (ValPC) \n",
      "84 epoch \n",
      "4000/4000 [==============================] - 2s 449us/step - loss: 0.3653 - val_RMSE_in_Pc: 0.0027 - val_loss: 2.7811\n",
      "85 epoch \n",
      "4000/4000 [==============================] - 2s 451us/step - loss: 0.3675 - val_RMSE_in_Pc: 0.0023 - val_loss: 2.8225\n",
      "86 epoch \n",
      "4000/4000 [==============================] - 2s 450us/step - loss: 0.3512 - val_RMSE_in_Pc: 0.0021 - val_loss: 2.8702\n",
      "87 epoch \n",
      "4000/4000 [==============================] - 2s 451us/step - loss: 0.3302 - val_RMSE_in_Pc: 0.0021 - val_loss: 2.8319\n",
      "88 epoch \n",
      "4000/4000 [==============================] - 2s 451us/step - loss: 0.3224 - val_RMSE_in_Pc: 0.0081 - val_loss: 2.9216\n",
      "89 epoch \n",
      "4000/4000 [==============================] - 2s 464us/step - loss: 0.3361 - val_RMSE_in_Pc: 0.0057 - val_loss: 2.8971\n",
      "90 epoch \n",
      "4000/4000 [==============================] - 2s 452us/step - loss: 0.3218 - val_RMSE_in_Pc: 0.0080 - val_loss: 2.9599\n",
      "91 epoch \n",
      "4000/4000 [==============================] - 2s 453us/step - loss: 0.3347 - val_RMSE_in_Pc: 0.0094 - val_loss: 2.9086\n",
      "92 epoch \n",
      "4000/4000 [==============================] - 2s 447us/step - loss: 0.3077 - val_RMSE_in_Pc: 0.0056 - val_loss: 2.9627\n",
      "93 epoch \n",
      "4000/4000 [==============================] - 2s 452us/step - loss: 0.2954 - val_RMSE_in_Pc: 0.0079 - val_loss: 2.9829\n",
      "94 epoch \n",
      "4000/4000 [==============================] - 2s 454us/step - loss: 0.3015 - val_RMSE_in_Pc: 0.0086 - val_loss: 2.9809\n",
      "95 epoch \n",
      "4000/4000 [==============================] - 2s 453us/step - loss: 0.2969 - val_RMSE_in_Pc: 0.0067 - val_loss: 3.0456\n",
      "96 epoch \n",
      "4000/4000 [==============================] - 2s 450us/step - loss: 0.2807 - val_RMSE_in_Pc: 0.0060 - val_loss: 3.0462\n",
      "97 epoch \n",
      "4000/4000 [==============================] - 2s 452us/step - loss: 0.2730 - val_RMSE_in_Pc: 0.0080 - val_loss: 3.0295\n",
      "98 epoch \n",
      "4000/4000 [==============================] - 2s 453us/step - loss: 0.2753 - val_RMSE_in_Pc: 0.0111 - val_loss: 3.0498\n",
      "99 epoch \n",
      "4000/4000 [==============================] - 2s 454us/step - loss: 0.2619 - val_RMSE_in_Pc: 0.0139 - val_loss: 3.1257\n",
      "\n",
      "The last model is saved in the following file path:\n",
      "D:/RESULTS/last_model_NPWE4i_scheme1_case1.h5\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\n",
    "from datetime import datetime\n",
    "from keras.utils import generic_utils\n",
    "import math\n",
    "\n",
    "save_model_address = save_dir+'model_'+model_name\n",
    "save_history_address = save_dir+'history_'+model_name+'.npy'\n",
    "save_last_epoch_address = save_dir+'last_model_'+model_name+'.h5'\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "NUM_4AFC = 100\n",
    "ITER = 100\n",
    "human_Pc = np.asarray([0.8086, 0.7814, 0.7600, 0.8514, 0.7971, 0.7400, 0.8914, 0.8571, 0.8114, 0.9286, 0.7929, 0.7186])\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "model_4AFC.compile(optimizer=opt,\n",
    "                   loss = 'mean_squared_error'\n",
    "                            )\n",
    "\n",
    "print(f'The checkpoint is saved in the following address:\\n{save_model_address}')\n",
    "\n",
    "best_ValLoss = np.Inf\n",
    "best_ValPc = np.inf\n",
    "best_TrainLoss = np.inf\n",
    "history = {}\n",
    "\n",
    "num_samples = labels.shape[0]\n",
    "\n",
    "for epochs in range(NUM_EPOCHS):\n",
    "    print (f\"{epochs} epoch \")\n",
    "    progbar = generic_utils.Progbar(num_samples)\n",
    "    \n",
    "#     new_learing_rate = step_decay(epochs)\n",
    "#     K.set_value(model_4AFC.optimizer.lr, new_learing_rate)  # set new lr\n",
    "    \n",
    "    np.random.seed(epochs)\n",
    "    idx_seq = np.random.permutation(num_samples)\n",
    "    imgs_ = imgs[idx_seq,...]\n",
    "    labels_ = labels[idx_seq,...]\n",
    "    \n",
    "    train_loss_list = []\n",
    "    for iters in range(math.ceil(num_samples/(BATCH_SIZE))): # iteration within epoch\n",
    "\n",
    "        last_idx = min((iters+1)*BATCH_SIZE, num_samples)\n",
    "        train_loss_temp = model_4AFC.train_on_batch(\n",
    "                                                    imgs_[iters*BATCH_SIZE:last_idx,...], \n",
    "                                                    labels_[iters*BATCH_SIZE:last_idx,...]           \n",
    "                                                   )\n",
    "        train_loss_temp = [train_loss_temp]\n",
    "        train_loss_list.append(train_loss_temp)\n",
    "        \n",
    "        if last_idx == num_samples:\n",
    "            progbar.add(last_idx-iters*BATCH_SIZE-2, values=[(n, v) for (n,v) in zip(model_4AFC.metrics_names, train_loss_temp)])\n",
    "        else:\n",
    "            progbar.add(last_idx-iters*BATCH_SIZE, values=[(n, v) for (n,v) in zip(model_4AFC.metrics_names, train_loss_temp)])\n",
    "    \n",
    "    train_loss_mean = np.asarray(train_loss_list)\n",
    "    train_loss_mean = np.mean(train_loss_mean,axis=0)\n",
    "    \n",
    "    for i in range(len(train_loss_mean)):\n",
    "        k = model_4AFC.metrics_names[i]\n",
    "        history.setdefault(k, []).append(train_loss_mean[i])\n",
    "\n",
    "\n",
    "    # validation RMSE in Pc\n",
    "    val_pred = model_4AFC.predict(imgs_val)\n",
    "\n",
    "    Pc_CNN = np.zeros((len(train_list), ITER))\n",
    "    Pc_target = np.zeros((len(train_list),))\n",
    "    for k in range(len(train_list)):\n",
    "        Pc_target[k] = human_Pc[int(train_list[k])-1]\n",
    "        np.random.seed(1)\n",
    "        t1_raw = val_pred[2*k*N_VA:(2*k+1)*N_VA]\n",
    "        t0_raw = val_pred[(2*k+1)*N_VA:2*(k+1)*N_VA] \n",
    "\n",
    "        for l in range(ITER):\n",
    "            idx_seq1 = np.random.permutation(N_VA)\n",
    "            idx_seq0 = np.random.permutation(N_VA)\n",
    "            t1_raw = t1_raw[idx_seq1]\n",
    "            t0_raw = t0_raw[idx_seq0]\n",
    "\n",
    "            prediction_4AFC = np.concatenate((t1_raw[0:NUM_4AFC], \n",
    "                                              t0_raw[0:NUM_4AFC], \n",
    "                                              t0_raw[NUM_4AFC:NUM_4AFC*2], \n",
    "                                              t0_raw[NUM_4AFC*2:NUM_4AFC*3]),axis=1)\n",
    "\n",
    "            answer_CNN = np.argmax(prediction_4AFC,axis=1)\n",
    "            Pc_CNN[k, l] = np.sum(answer_CNN==0) / NUM_4AFC\n",
    "            \n",
    "\n",
    "    val_loss = np.sqrt(np.mean((np.mean(Pc_CNN, axis = 1) - Pc_target) **2))\n",
    "    progbar.add(1, values=[('val_RMSE_in_Pc', val_loss)])\n",
    "    \n",
    "    history.setdefault('val_RMSE_in_Pc',[]).append(val_loss)\n",
    "\n",
    "    # validation loss\n",
    "\n",
    "    val_loss = model_4AFC.evaluate(imgs_val, \n",
    "                                   labels_val,\n",
    "                                   batch_size=BATCH_SIZE,\n",
    "                                   verbose=0)\n",
    "    val_loss = [val_loss]\n",
    "    progbar.add(1, values=[('val_'+n, v) for (n,v) in zip(model_4AFC.metrics_names, val_loss)])\n",
    "    \n",
    "    for i in range(len(val_loss)):\n",
    "        k = 'val_'+model_4AFC.metrics_names[i]\n",
    "        history.setdefault(k, []).append(val_loss[i])\n",
    "\n",
    "    if epochs > 5:\n",
    "        current_ValPc = history.get('val_RMSE_in_Pc')[-1]\n",
    "        if current_ValPc < best_ValPc:\n",
    "            best_ValPc = current_ValPc\n",
    "            model_4AFC.save(save_model_address+'.h5', overwrite=True)\n",
    "            print('Model Saved (ValPC) ')\n",
    "        \n",
    "#     current_ValLoss = history.get('val_loss')[-1]\n",
    "#     if current_ValLoss < best_ValLoss:\n",
    "#         best_ValLoss = current_ValLoss\n",
    "#         model_4AFC.save(save_model_address+'_valLoss.h5', overwrite=True)\n",
    "#         print('Model Saved (ValLoss)')\n",
    "    \n",
    "#     if epochs > 140:\n",
    "#         current_TrainLoss = history.get('loss')[-1]\n",
    "#         if current_TrainLoss < best_TrainLoss:\n",
    "#             best_TrainLoss = current_TrainLoss\n",
    "#             model_4AFC.save(save_model_address+'_trainLoss.h5', overwrite=True)\n",
    "#             print('Model Saved (TrainLoss)')\n",
    "\n",
    "print(f'\\nThe last model is saved in the following file path:\\n{save_last_epoch_address}')\n",
    "model_4AFC.save(save_last_epoch_address)\n",
    "np.save(save_history_address, history)\n",
    "\n",
    "# print(history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loading Testing Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_processing == true.\n",
      "Testing image shape: (2000, 129, 129, 1)\n",
      "Testing label shape: (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "test_list = {\n",
    "    1: [data_case],\n",
    "    2: list(range(6*(data_case-1)+1,6*data_case+1)),\n",
    "    3: list(range(12-6*data_case+1,12-6*(data_case-1)+1))\n",
    "}[training_testing_scheme]\n",
    "\n",
    "N_PA = 4000 # number of image pairs (g1 and g0)\n",
    "N_TR = 2000 # number of training pairs\n",
    "N_VA = 1000 # number of validation pairs\n",
    "N_TE = 1000 # number of testing pairs\n",
    "\n",
    "input_processing = True # make DC component to zero\n",
    "\n",
    "random_seed_number = 3 # shuffling training and validation sets.\n",
    "np.random.seed(random_seed_number)\n",
    "idx_seq1 = np.random.permutation(N_TR+N_VA)\n",
    "idx_seq0 = np.random.permutation(N_TR+N_VA)\n",
    "\n",
    "for i in range(0,len(test_list)):\n",
    "\n",
    "    filename = data_dir+'N'+str(test_list[i])+'_g1.mat'\n",
    "    f = h5py.File(filename,'r')\n",
    "    g1_temp = np.asarray(f['g1'])\n",
    "    \n",
    "    filename = data_dir+'N'+str(test_list[i])+'_g0.mat'\n",
    "    f = h5py.File(filename,'r')\n",
    "    g0_temp = np.asarray(f['g0'])\n",
    "    \n",
    "    filename = data_dir+'label_N'+str(test_list[i])+'_'+labeling_method+'.mat'\n",
    "    f = io.loadmat(filename)\n",
    "    t1_temp = np.asarray(f['t1'])\n",
    "    t1_temp = np.transpose(t1_temp, (1,0))\n",
    "    t0_temp = np.asarray(f['t0'])\n",
    "    t0_temp = np.transpose(t0_temp, (1,0))\n",
    "            \n",
    "    if i == 0:\n",
    "        imgs_test = np.concatenate((g1_temp[N_TR+N_VA:N_TR+N_VA+N_TE,:,:],g0_temp[N_TR+N_VA:N_TR+N_VA+N_TE,:,:]),axis=0)\n",
    "        labels_test = np.concatenate((t1_temp[N_TR+N_VA:N_TR+N_VA+N_TE],t0_temp[N_TR+N_VA:N_TR+N_VA+N_TE]),axis=0)\n",
    "        \n",
    "    else:\n",
    "        imgs_test = np.concatenate((imgs_test, g1_temp[N_TR+N_VA:N_TR+N_VA+N_TE,:,:],g0_temp[N_TR+N_VA:N_TR+N_VA+N_TE,:,:]), axis = 0)\n",
    "        labels_test = np.concatenate((labels_test, t1_temp[N_TR+N_VA:N_TR+N_VA+N_TE],t0_temp[N_TR+N_VA:N_TR+N_VA+N_TE]), axis = 0) \n",
    "\n",
    "\n",
    "imgs_test = np.transpose(imgs_test, (0,2,1)) \n",
    "imgs_test = imgs_test[...,np.newaxis]\n",
    "\n",
    "if input_processing:\n",
    "    print('input_processing == true.')\n",
    "    for i in range(0, imgs_test.shape[0]):\n",
    "        imgs_test[i,:,:,0] = imgs_test[i,:,:,0] - np.mean(imgs_test[i,:,:,0])\n",
    "        \n",
    "print(f\"Testing image shape: {imgs_test.shape}\")\n",
    "print(f\"Testing label shape: {labels_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loading Model Observer\n",
    "\n",
    "* load_model_address: file path name of your model observer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 129, 129, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 65, 65, 2)         340       \n",
      "_________________________________________________________________\n",
      "lrelu_conv0 (LeakyReLU)      (None, 65, 65, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 33, 33, 4)         1356      \n",
      "_________________________________________________________________\n",
      "lrelu_conv1 (LeakyReLU)      (None, 33, 33, 4)         0         \n",
      "_________________________________________________________________\n",
      "flattening (Flatten)         (None, 4356)              0         \n",
      "_________________________________________________________________\n",
      "output_value (Dense)         (None, 1)                 4357      \n",
      "=================================================================\n",
      "Total params: 6,053\n",
      "Trainable params: 6,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model, Model\n",
    "\n",
    "load_model_address = save_model_address\n",
    "\n",
    "model_loaded =  load_model(load_model_address+'.h5',\n",
    "                           custom_objects={'DigitCapsuleLayer': DigitCapsuleLayer, 'norm': norm, 'squashing': squashing})\n",
    "\n",
    "model_loaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing Model Observer\n",
    "\n",
    "* The model observer performs the 4-AFC detection tasks where it choose the image with the highest decision variable as a signal-present image among one signal-present and three signal-absent images in each trial.\n",
    "\n",
    "---\n",
    "\n",
    "* save_results_address: file path name of 4-AFC testing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pc of CNN = [0.8217]\n",
      "Pc of human observers (target) = [0.8086]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "save_results_address = load_model_address+'_4AFC'\n",
    "\n",
    "prediction_test = model_loaded.predict(imgs_test)\n",
    "\n",
    "human_Pc = np.asarray([0.8086, 0.7814, 0.7600, 0.8514, 0.7971, 0.7400, 0.8914, 0.8571, 0.8114, 0.9286, 0.7929, 0.7186])\n",
    "\n",
    "NUM_4AFC = 100\n",
    "ITER = 100\n",
    "\n",
    "Pc_CNN = np.zeros((len(test_list), ITER))\n",
    "Pc_NPWE = np.zeros((len(test_list), ITER))\n",
    "\n",
    "o_CNN = []\n",
    "o_NPWE = []\n",
    "\n",
    "random_seeds = 2\n",
    "\n",
    "for j in range(0,len(test_list)):\n",
    "    np.random.seed(random_seeds)\n",
    "    for i in range(0,ITER):\n",
    "\n",
    "        idx_seq1 = np.random.permutation(N_TE)\n",
    "        idx_seq0 = np.random.permutation(N_TE)\n",
    "\n",
    "        prediction_g1 = prediction_test[2*j*N_TE+idx_seq1] # Signal Present\n",
    "        labels_g1 = labels_test[2*j*N_TE+idx_seq1]\n",
    "\n",
    "        prediction_g0 = prediction_test[(2*j+1)*N_TE+idx_seq0] # Signal Absent\n",
    "        labels_g0 = labels_test[(2*j+1)*N_TE+idx_seq0]\n",
    "\n",
    "        prediction_4AFC = np.concatenate((prediction_g1[0:NUM_4AFC], \n",
    "                                          prediction_g0[0:NUM_4AFC], \n",
    "                                          prediction_g0[NUM_4AFC:NUM_4AFC*2], \n",
    "                                          prediction_g0[NUM_4AFC*2:NUM_4AFC*3]),axis=1)\n",
    "        label_4AFC = np.concatenate((labels_g1[0:NUM_4AFC], \n",
    "                                     labels_g0[0:NUM_4AFC], \n",
    "                                     labels_g0[NUM_4AFC:NUM_4AFC*2], \n",
    "                                     labels_g0[NUM_4AFC*2:NUM_4AFC*3]),axis=1)\n",
    "\n",
    "        answer_CNN = np.argmax(prediction_4AFC,axis=1)\n",
    "        answer_NPWE = np.argmax(label_4AFC,axis=1)\n",
    "\n",
    "        o_CNN = np.append(o_CNN, answer_CNN==0)\n",
    "        o_NPWE = np.append(o_NPWE, answer_NPWE==0)\n",
    "\n",
    "        Pc_CNN[j, i] = np.sum(answer_CNN==0) / NUM_4AFC\n",
    "        Pc_NPWE[j, i] = np.sum(answer_NPWE==0) / NUM_4AFC\n",
    "\n",
    "print(f'Pc of CNN = {np.mean(Pc_CNN, axis = 1)}')\n",
    "print(f'Pc of human observers (target) = {human_Pc[[x - 1 for x in test_list]]}')\n",
    "\n",
    "\n",
    "from scipy import io\n",
    "io.savemat(save_results_address+'.mat',\n",
    "           mdict={'output_test': prediction_test, 'label_test':labels_test, 'o_output': o_CNN, 'o_label': o_NPWE,'Pc_output': Pc_CNN, 'Pc_label':Pc_NPWE})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
